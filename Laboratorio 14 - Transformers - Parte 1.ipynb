{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHopPtVaNF1K"
      },
      "source": [
        "# **Diplomado IA: Inteligencia Artificial II - Parte 1**. <br> Laboratorio 1: Redes Relacionales y Transformers\n",
        "---\n",
        "---\n",
        "\n",
        "**Profesor:**\n",
        "- Felipe del Río\n",
        "\n",
        "**Ayudante:**\n",
        "- Bianca del Solar\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIdAKAdELPSl"
      },
      "source": [
        "# **Instrucciones Generales**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmhnKlt8Ns7A"
      },
      "source": [
        "El siguiente práctico será **individual**. Solo uno debe realizar la entrega. El formato de entregar es el **archivo .ipynb con todas las celdas ejecutadas**. Todas las preguntas deben ser respondida en celdas de texto. No se aceptará el _output_ de una celda de código como respuesta.\n",
        "\n",
        "**Nombre:** COMPLETAR\n",
        "\n",
        "**Fecha de entrega: Viernes 30 de Junio.**\n",
        "\n",
        "El siguiente práctico cuenta con 3 secciones donde cada una contendrá 1 o más actividades a realizar. Algunas actividades correspondrán a escribir código y otras a responder preguntas.\n",
        "\n",
        "**Importante.** Para facilitar su ejecución, cada sección puede ser ejecutada independientemente.\n",
        "\n",
        "Se recomienda **fuertemente** revisar las secciones donde se entrega código porque algunas actividades de código pueden reutilizar el mismo código pero con cambios en algunas líneas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEloa5uXLIPK"
      },
      "source": [
        "# **Agenda**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "toc",
        "id": "DGlX5q_pQYRa"
      },
      "source": [
        ">[Diplomado IA: Inteligencia Artificial II - Parte 1.  Laboratorio 1: Redes Relacionales y Transformers](#scrollTo=tHopPtVaNF1K)\n",
        "\n",
        ">[Instrucciones Generales](#scrollTo=uIdAKAdELPSl)\n",
        "\n",
        ">[Agenda](#scrollTo=kEloa5uXLIPK)\n",
        "\n",
        ">[Parte I: Inspeccionando las atenciones de un Transformer](#scrollTo=ZS3cYFT2TWB9)\n",
        "\n",
        ">>[Preámbulo](#scrollTo=0dBeU4b818s4)\n",
        "\n",
        ">>[Representación del Input para BERT](#scrollTo=WlA3k2R7gPWV)\n",
        "\n",
        ">>[NER](#scrollTo=ukXvd54RjC_4)\n",
        "\n",
        ">>[Visualización de Atenciones](#scrollTo=M7aoVKrWlLbp)\n",
        "\n",
        ">>>[Head View](#scrollTo=Z4COgQK0BAsp)\n",
        "\n",
        ">>>[Model View](#scrollTo=J9e2nT-FD_kH)\n",
        "\n",
        ">>>[Neuron View](#scrollTo=in3biNv0pJV_)\n",
        "\n",
        ">>>[Actividad 1](#scrollTo=7krb_CeKqANH)\n",
        "\n",
        ">[Parte II: Inspeccionando el decoder de un Transformer](#scrollTo=6Yf6uthYE2pA)\n",
        "\n",
        ">>[Preámbulo](#scrollTo=wJdA60kAbgHP)\n",
        "\n",
        ">>[Traducción EN-DE](#scrollTo=oyk-K3pjXrwX)\n",
        "\n",
        ">>[Actividad 2](#scrollTo=flpPAFaJfm5H)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS3cYFT2TWB9"
      },
      "source": [
        "# Parte I: Inspeccionando las atenciones de un Transformer\n",
        "\n",
        "\n",
        "\n",
        "En este laboratorio exploraremos un modelo de Transformer, BETO, el cual está basado en BERT y preentrenado en un corpus en español. Utilizaremos un modelo que ya fue refinado para la tarea de NER en español.\n",
        "\n",
        "**NER (*Named Entity Recognition*)**, es una tarea que consiste en encontrar y detectar entidades nombradas (personas, organizaciones, etc.) dentro de un texto, además de clasificar a que tipo corresponde. Es sumemente útil para identificar que entidades están presentes en nuestros textos y poder un análisis más profundo en base a ellos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dBeU4b818s4"
      },
      "source": [
        "## Preámbulo\n",
        "\n",
        "Primero debemos descargar, instalar e importar las distintas librerías que utilizaremos para este laboratorio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d6wWanXrhWa"
      },
      "outputs": [],
      "source": [
        "!pip install bertviz==1.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCKW2hAUyK_4"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "import IPython\n",
        "from bertviz import head_view, model_view\n",
        "from bertviz.neuron_view import show\n",
        "import spacy\n",
        "from spacy.vocab import Vocab\n",
        "from spacy.tokens import Doc, Span\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import BertTokenizer, BertModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COboZlrQtbVv"
      },
      "source": [
        "También crearemos algunas funciones auxiliares para el laboratorio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mv6H9QK9yLLe"
      },
      "outputs": [],
      "source": [
        "# Funciones auxiliares para la visualización de los resultados del modelo para NER\n",
        "\n",
        "LABEL_LIST = [\n",
        "    \"B-LOC\",    # Beginning of a location right after another location\n",
        "    \"B-MISC\",   # Beginning of a miscellaneous entity right after another miscellaneous entity\n",
        "    \"B-ORG\",    # Beginning of an organisation right after another organisation\n",
        "    \"B-PER\",    # Beginning of a person's name right after another person's name\n",
        "    \"I-LOC\",    # Location\n",
        "    \"I-MISC\",   # Miscellaneous entity\n",
        "    \"I-ORG\",    # Organisation\n",
        "    \"I-PER\",    # Person's name\n",
        "    \"O\"         # Outside of a named entity\n",
        "]\n",
        "\n",
        "# Construimos el Doc para uso de Spacy\n",
        "def build_doc(tokens, spaces, vocab):\n",
        "    tokens = [token.replace('##', '') for token in tokens] # Remove ## start in word pieces\n",
        "    vocab = Vocab(strings=vocab)\n",
        "    doc = Doc(vocab=vocab, words=tokens, spaces=spaces)\n",
        "    return doc\n",
        "\n",
        "# Obtenemos la lista de `spaces`, con `True` para los tokens que están seguidos de espacios\n",
        "def get_spaces(tokens):\n",
        "    spaces = []\n",
        "    for i, token in enumerate(tokens):\n",
        "        if i + 1 == len(tokens):\n",
        "            spaces.append(False)\n",
        "            break\n",
        "\n",
        "        next_token = tokens[i+1]\n",
        "        if next_token in string.punctuation:\n",
        "            spaces.append(False)\n",
        "            continue\n",
        "        if next_token.startswith('##'):\n",
        "            spaces.append(False)\n",
        "            continue\n",
        "\n",
        "        spaces.append(True)\n",
        "\n",
        "    return spaces\n",
        "\n",
        "# Transformar de una lista de entidades a un diccionarion con las entidades\n",
        "# interesantes y sus ubicaciones\n",
        "def get_entity_locs(entities):\n",
        "    def gettype(ent):\n",
        "        return ent.replace('B-', '').replace('I-', '')\n",
        "\n",
        "    ents = []\n",
        "    start, end = 0, 0\n",
        "    type_ = ''\n",
        "    for i, ent in enumerate(entities):\n",
        "        if ent == 'O':\n",
        "            if type_:\n",
        "                ents.append((start, end, type_))\n",
        "            start, end = 0, 0\n",
        "            type_ = ''\n",
        "\n",
        "        if ent.startswith('B-'):\n",
        "            if type_:\n",
        "                ents.append((start, end, type_))\n",
        "            start, end = i, i\n",
        "            type_ = gettype(ent)\n",
        "\n",
        "        if type_ and ent.startswith('I-') and gettype(ent) == type_:\n",
        "            end = i\n",
        "\n",
        "        if i + 1 == len(entities) and type_:\n",
        "            ents.append((start, end, type_))\n",
        "\n",
        "    return ents\n",
        "\n",
        "# Añadimos las entidades al objeto Doc\n",
        "def add_entities(doc, entity_locs):\n",
        "    doc_ents = []\n",
        "    for start, end, type_ in entity_locs:\n",
        "        span = Span(doc, start=start, end=end+1, label=type_)\n",
        "        doc_ents.append(span)\n",
        "\n",
        "    doc.ents = doc_ents\n",
        "    return doc\n",
        "\n",
        "# Integramos el pipeline completo para visualizar las entidades\n",
        "def build_for_vis(tokens, predictions, special_tokens=None):\n",
        "    special_tokens = [] if special_tokens is None else special_tokens\n",
        "\n",
        "    ents = [LABEL_LIST[prediction] for token, prediction in zip(tokens, predictions) if token not in special_tokens]\n",
        "    tokens = [token for token in tokens if token not in special_tokens]\n",
        "\n",
        "    spaces = get_spaces(tokens)\n",
        "    vocab = list(tokenizer.vocab.keys())\n",
        "    doc = build_doc(tokens, spaces, vocab=vocab)\n",
        "\n",
        "    entity_locs = get_entity_locs(ents)\n",
        "    doc = add_entities(doc, entity_locs)\n",
        "    return doc\n",
        "\n",
        "# Funciones auxiliares para la visualización de atenciones\n",
        "\n",
        "def call_html(view='head'):\n",
        "    assert view in ['head', 'model', 'neuron']\n",
        "    d3_version = {\n",
        "        'head': '3.5.8', 'model': '5.7.0', 'neuron': '5.7.0'\n",
        "    }[view]\n",
        "    load_libs_html = f'''\n",
        "            <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "            <script>\n",
        "            requirejs.config({{\n",
        "                paths: {{\n",
        "                base: '/static/base',\n",
        "                \"d3\": \"https://cdnjs.cloudflare.com/ajax/libs/d3/{d3_version}/d3.min\",\n",
        "                jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
        "                }},\n",
        "            }});\n",
        "            </script>\n",
        "            '''\n",
        "    display(IPython.core.display.HTML(load_libs_html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlA3k2R7gPWV"
      },
      "source": [
        "## Representación del Input para BERT\n",
        "\n",
        "Primero que todo, creamos el modelo y tokenizador a utilizar. Como vimos en clases, un modelo del tipo BERT requiere formatear la entrada agregando tokens especiales que cumplen algunas funciones. Para lograr este formato de forma sencilla, utilizaremos el tokenizador correspondiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOlEpzCyTWh5"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model_type = 'bert'\n",
        "model_version = 'mrm8488/bert-spanish-cased-finetuned-ner' # Pesos a utilizar\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_version)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_version, output_attentions=True)\n",
        "model.to(device)\n",
        "\n",
        "special_tokens = tokenizer.special_tokens_map.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeKoypEMYYE_"
      },
      "outputs": [],
      "source": [
        "text = 'Eduardo Vargas le metió un gol a España en el mundial de Brasil.'\n",
        "\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "inputs.to(device)\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWMfMB4rv8pR"
      },
      "source": [
        "A continuación utilizaremos el tokenizador que nos provee la librería Transformers para entender mejor como se construye el input para un modelo basado en BERT.\n",
        "\n",
        "Podemos observar cual es el resultado de agregar estos tokens a nuestro texto. Para esto usamos el *hack*, de codificar y luego decodificar nuestro texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lalo7PzVYtqR"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(tokenizer.encode(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUqUt6ewwPK-"
      },
      "source": [
        "Sabemos que BERT está pensado para utilizar varias frases en el input, como por ejemplo para tareas de pregunta-respuesta podemos ver el resultado de la misma forma, entregandole el segundo texto como input al tokenizador."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ_zkrWfinBL"
      },
      "outputs": [],
      "source": [
        "text2 = 'Y Alexis Sánchez a Brasil en octavos, en Belo Horizonte'\n",
        "tokenizer.decode(tokenizer.encode(text, text2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G62YZvdYwjce"
      },
      "source": [
        "También, podemos ver la forma en que se hace tokenización a nivel de sub-palabras, es decir que existen tokens que corresponden a partes de palabras en vez de la palabra completa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nmsk7bkSYcbo"
      },
      "outputs": [],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j803THZWwsCK"
      },
      "source": [
        "El tokenizador nos ayuda también a preparar los otros inputs que entrarán al modelo, como lo son por ejemplo los *segment embeddings*. A continuación se muestran tanto para una frase como para dos.\n",
        "\n",
        "\n",
        "\n",
        "![](https://miro.medium.com/max/1000/1*EKzyGf_l0e57XN491_YAyg.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yHV24axgqtF"
      },
      "outputs": [],
      "source": [
        "sample_input = tokenizer(text, return_tensors=\"pt\")\n",
        "sample_input['token_type_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ccY05ciZuoT"
      },
      "outputs": [],
      "source": [
        "sample_input2 = tokenizer(text, text2, return_tensors=\"pt\")\n",
        "sample_input2['token_type_ids']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukXvd54RjC_4"
      },
      "source": [
        "## NER\n",
        "\n",
        "Ahora utilicemos el modelo que creamos para la tarea de NER y veamos las predicciones que realiza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XikOmnfcvlfg"
      },
      "outputs": [],
      "source": [
        "outputs = model(**inputs)[0]\n",
        "predictions = torch.argmax(outputs, dim=2)\n",
        "predictions = predictions[0].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MejzNrekGiHG"
      },
      "outputs": [],
      "source": [
        "labeled_text = build_for_vis(tokens, predictions, special_tokens=special_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnpGPsHIEH38"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy\n",
        "\n",
        "displacy.render(labeled_text, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9lwKYbzqdcv"
      },
      "source": [
        "Puede utilizar el código a continuación para obtener una visualización en base al texto que ud. desee. Para esto debe asignarlo a la variable `texto`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj5QlUHJG0ts"
      },
      "outputs": [],
      "source": [
        "texto = '' #@param {type:\"string\"}\n",
        "\n",
        "if texto:\n",
        "    tokens = tokenizer.tokenize(\n",
        "        tokenizer.decode(tokenizer.encode(texto)))\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\")\n",
        "    inputs.to(device)\n",
        "\n",
        "    outputs = model(**inputs)[0]\n",
        "    predictions = torch.argmax(outputs, dim=2)\n",
        "    predictions = predictions[0].tolist()\n",
        "\n",
        "    labeled_text = build_for_vis(\n",
        "        tokens, predictions, special_tokens=special_tokens)\n",
        "    displacy.render(labeled_text, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7aoVKrWlLbp"
      },
      "source": [
        "## Visualización de Atenciones\n",
        "\n",
        "Como sabemos, la arquitectura de un modelo Transformer está construída en gran parte sobre atenciones. Esto nos da la posibilidad de poder visualizar estas atenciones para poder hacernos una idea de lo que está pasando dentro del modelo mismo. Para generar las visualizaciones nos ayudará el repositiorio [BertViz](https://github.com/jessevig/bertviz).\n",
        "\n",
        "**Importante.** Es posible que las visualizaciones a continuación no se carguen correctamente la primera vez que se ejecuta la celda, en dicho caso intenten ejecutar nuevamente la celda."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4COgQK0BAsp"
      },
      "source": [
        "### Head View\n",
        "\n",
        "Primero usamos la visualización del tipo `head_view` para ver los patrones de atención de una o más *heads* para una capa dada.\n",
        "\n",
        "En esta visualización podemos ver la representación de la palabra que está siendo actualizada (*query*) a la **izquierda**, mientras que las palabras a las cuales se le pone atención (*key, value*) a la **derecha** de la visualización.\n",
        "\n",
        "Con el *dropdown* podemos cambiar la capa en la cual nos fijamos y cada color significa una *head* distinta del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZAXH7hWyt58"
      },
      "outputs": [],
      "source": [
        "# Head View\n",
        "texto = 'Eduardo Vargas le metió un gol a España en el mundial de Brasil.'\n",
        "\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(texto)))\n",
        "inputs = tokenizer(texto, return_tensors=\"pt\")\n",
        "inputs.to(device)\n",
        "\n",
        "token_type_ids = inputs['token_type_ids']\n",
        "input_ids = inputs['input_ids']\n",
        "\n",
        "attention = model(**inputs)[-1]\n",
        "input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "call_html(view='head')\n",
        "\n",
        "head_view(attention, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD-pUL3hCDsU"
      },
      "source": [
        "Puede utilizar el código a continuación para obtener una visualización en base al texto que ud. desee. Para esto debe asignarlo a la variable `texto`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcuXERgtB8H8"
      },
      "outputs": [],
      "source": [
        "# Head View\n",
        "texto = '' #@param {type:\"string\"}\n",
        "\n",
        "if texto:\n",
        "    tokens = tokenizer.tokenize(\n",
        "        tokenizer.decode(tokenizer.encode(texto)))\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\")\n",
        "    inputs.to(device)\n",
        "\n",
        "    token_type_ids = inputs['token_type_ids']\n",
        "    input_ids = inputs['input_ids']\n",
        "\n",
        "    attention = model(**inputs)[-1]\n",
        "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "    call_html(view='head')\n",
        "\n",
        "    head_view(attention, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9e2nT-FD_kH"
      },
      "source": [
        "### Model View\n",
        "\n",
        "A continuación  tenemos una visualización muy similar a  la anterior, sin embargo esta muestra cada capa y head del modelo por separado.\n",
        "\n",
        "Cada fila está asociada a una capa del modelo (en orden creciente) mientras que cada columna corresponde a una *head* distinta en dicha capa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QZI2uz-zE8Zn"
      },
      "outputs": [],
      "source": [
        "texto = 'Eduardo Vargas le metió un gol a España en el mundial de Brasil.'\n",
        "\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(texto)))\n",
        "inputs = tokenizer(texto, return_tensors=\"pt\")\n",
        "inputs.to(device)\n",
        "\n",
        "token_type_ids = inputs['token_type_ids']\n",
        "input_ids = inputs['input_ids']\n",
        "attention = model(**inputs)[-1]\n",
        "input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "call_html(view='model')\n",
        "\n",
        "model_view(attention, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f8zHo3ECPWK"
      },
      "source": [
        "A continuación puede utilizar el código a continuación para obtener una visualización en base al texto que ud. desee. Para esto debe asignarlo a la variable `texto`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toeq1Nc27iWZ"
      },
      "outputs": [],
      "source": [
        "texto = '' #@param {type:\"string\"}\n",
        "\n",
        "if texto:\n",
        "    tokens = tokenizer.tokenize(\n",
        "        tokenizer.decode(tokenizer.encode(texto)))\n",
        "    inputs = tokenizer(texto, return_tensors=\"pt\")\n",
        "    inputs.to(device)\n",
        "\n",
        "    token_type_ids = inputs['token_type_ids']\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention = model(**inputs)[-1]\n",
        "    input_id_list = input_ids[0].tolist() # Batch index 0\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "    call_html(view='model')\n",
        "\n",
        "    model_view(attention, tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in3biNv0pJV_"
      },
      "source": [
        "### Neuron View\n",
        "\n",
        "A continuación tenemos una visualización muy similar a las anteriores, principalmente a la primera. Sin embargo, en esta podemos visualizar de mucho mejor forma las activaciones que están generando para cada una de las representaciones y como estas afectan la atención.\n",
        "\n",
        "Este gráfico se interpreta de la misma manera que el primero (*Head View*), sin embargo podemos hacer click en las palabras de la izquierda para visualizar el cálculo de cada atención.\n",
        "\n",
        "**Importante.** Este modelo trabaja con una versión modificada de la librería Transformer que hemos utilizada (notar los `import`'s a continuación), es por eso que las frases a utilizar son en inglés pues solo contamos con los modelos pre-entrenados base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juNXbazl16D5"
      },
      "outputs": [],
      "source": [
        "from bertviz.transformers_neuron_view import BertModel as VizBertModel, BertTokenizer as VizBertTokenizer\n",
        "from bertviz.neuron_view import show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQL4ONM4o4nZ"
      },
      "outputs": [],
      "source": [
        "# Ojo: Puede haber problemas con la visualziación si es que las oraciones son muy largas.\n",
        "sentence_a = \"Alexis scored against Brazil in the World Cup.\"\n",
        "sentence_b = \"Pinilla's shot struck the crossbar in that match.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7lGFcIRQj7H"
      },
      "outputs": [],
      "source": [
        "nv_model_type = 'bert'\n",
        "nv_model_version = 'bert-base-uncased'\n",
        "\n",
        "do_lower_case = 'uncased' in nv_model_version\n",
        "tokenizer = VizBertTokenizer.from_pretrained(nv_model_version, do_lower_case=do_lower_case)\n",
        "model = VizBertModel.from_pretrained(nv_model_version)\n",
        "call_html(view='neuron')\n",
        "show(model, nv_model_type, tokenizer, sentence_a, sentence_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7krb_CeKqANH"
      },
      "source": [
        "### Actividad 1\n",
        "\n",
        "Descomente el código a continuación y elija una versión de BERT para probar la misma visualización que la obtenida anteriormente. Para esto debe definir correctamente la variable `nv_model_version`.\n",
        "\n",
        "Basta con la ejecución para la actividad. Debe ser una versión distinta a la ya utilizada, `'bert-base-uncased'`.\n",
        "\n",
        "**Importante:** Por limitaciones del sistema, no elijan modelos muy pesados para la visualización pues probablemente se caerán, principalmente eviten los modelos con `large` en el nombre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScNsw7RwX-XP"
      },
      "outputs": [],
      "source": [
        "# nv_model_type = 'bert'\n",
        "# nv_model_version = 'bert-base-uncased'\n",
        "\n",
        "# do_lower_case = 'uncased' in nv_model_version\n",
        "# tokenizer = VizBertTokenizer.from_pretrained(nv_model_version, do_lower_case=do_lower_case)\n",
        "# model = VizBertModel.from_pretrained(nv_model_version)\n",
        "# call_html(view='neuron')\n",
        "# show(model, nv_model_type, tokenizer, sentence_a, sentence_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q6GuYknzBYm"
      },
      "source": [
        "También responda **brevemente** las siguientes preguntas en base a la actividad realizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcNO8-C7zQit"
      },
      "source": [
        "**1. En las visualizaciones de las atenciones que vimos más arriba. ¿Por qué siempre se muestra la misma oración, tanto la que atiende con la que es atendida?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wd0jgzCgzR2N"
      },
      "outputs": [],
      "source": [
        "R = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBYX4TbezQvq"
      },
      "source": [
        "**2. En la visualización Neuron View ¿a qué corresponden los parámetros \"Layer\" y \"Head\"?**\n",
        "\n",
        "Parámetro Layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cSotQOIZzSQF"
      },
      "outputs": [],
      "source": [
        "R = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCT_1tGw1Pkj"
      },
      "source": [
        "Parámetro Head:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9aT5niEE1UCa"
      },
      "outputs": [],
      "source": [
        "R = '' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Yf6uthYE2pA"
      },
      "source": [
        "# Parte II: Inspeccionando el decoder de un Transformer\n",
        "\n",
        "En esta parte de la actividad inspeccionaremos la atención cruzada que realiza el decoder sobre el encoder. Esta atención nos dará una mejor idea de que está usando el modelo para generar texto en el decoder.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJdA60kAbgHP"
      },
      "source": [
        "## Preámbulo\n",
        "\n",
        "Primero debemos instalar las dependencias que usaremos durante la actividad y los checkpoints del modelo. Utilizaremos un modelo pre-entrenado que nos [provee OpenNMT](https://opennmt.net/Models-py/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNIa37rdvl1E"
      },
      "outputs": [],
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "!pip install git+https://github.com/OpenNMT/OpenNMT-py.git@v2.3.0 -q\n",
        "!mkdir -p checkpoints\n",
        "!wget -P checkpoints https://s3.amazonaws.com/opennmt-models/transformer-ende-wmt-pyOnmt.tar.gz\n",
        "!tar xzf checkpoints/transformer-ende-wmt-pyOnmt.tar.gz -C checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxCzJW4-P38Z"
      },
      "source": [
        "También descargaremos los datos que se utilizarán, en este caso el dataset entre inglés y alemán [WMT](http://www.statmt.org/wmt14/translation-task.html])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76PQ-x7mIA-8"
      },
      "outputs": [],
      "source": [
        "!mkdir -p data\n",
        "!wget -P data https://s3.amazonaws.com/opennmt-trainingdata/wmt_ende_sp.tar.gz\n",
        "!tar xzf data/wmt_ende_sp.tar.gz -C data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oY3bnANVI73"
      },
      "source": [
        "También importamos nuestras dependencias a nuestro entorno de trabajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlwWKiphvlxG"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import onmt\n",
        "from onmt.inputters.inputter import _load_vocab, _build_fields_vocab, get_fields\n",
        "from onmt.model_builder import build_model\n",
        "from onmt.models.model_saver import load_checkpoint\n",
        "from onmt.translate import GNMTGlobalScorer, Translator, TranslationBuilder\n",
        "from onmt.opts import dynamic_prepare_opts, translate_opts\n",
        "from onmt.utils.parse import ArgumentParser\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "seaborn.set_context(context=\"talk\")\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB3qu2BSVRt0"
      },
      "source": [
        "Debemos crear el archivo de configuración que utilizaremos con el modelo. Este archivo de configuración es una adaptación al indicado en la [documentación de OpenNMT](http://opennmt.net/OpenNMT-py/FAQ.html#how-do-i-use-the-transformer-model-do-you-support-multi-gpu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_znlcOebH6H7"
      },
      "outputs": [],
      "source": [
        "%%writefile checkpoints/config.yaml\n",
        "\n",
        "src_vocab: data/wmtende.vocab\n",
        "\n",
        "# Corpus opts:\n",
        "data:\n",
        "    train:\n",
        "        path_src: data/train.de\n",
        "        path_tgt: data/train.en\n",
        "\n",
        "# General opts\n",
        "save_model: foo\n",
        "save_checkpoint_steps: 10000\n",
        "valid_steps: 10000\n",
        "train_steps: 200000\n",
        "\n",
        "# Batching\n",
        "queue_size: 10000\n",
        "bucket_size: 32768\n",
        "world_size: 4\n",
        "gpu_ranks: [0, 1, 2, 3]\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 4096\n",
        "valid_batch_size: 8\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp32\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 2\n",
        "warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 8\n",
        "rnn_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czMYHzw4WAii"
      },
      "source": [
        "Finalmente definimos algunas funciones que nos ayudarán a simplificar el código de la actividad."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2wbsLRRvlug"
      },
      "outputs": [],
      "source": [
        "# Obtención del checkpoint en base a su path\n",
        "def get_checkpoint_data(checkpoint_path):\n",
        "    checkpoint = load_checkpoint(checkpoint_path)\n",
        "    fields = checkpoint['vocab']\n",
        "    opts = checkpoint['opt']\n",
        "    return checkpoint, fields, opts\n",
        "\n",
        "# Actualización de la configuración por defecto en base a las del checkpoint\n",
        "def update_opts(opts, config_path):\n",
        "    parser = ArgumentParser(description='translate.py')\n",
        "    dynamic_prepare_opts(parser, build_vocab_only=False)\n",
        "    translate_opts(parser)\n",
        "\n",
        "    base_args = ['-config', config_path,\n",
        "                 '-out_file', './out.txt',\n",
        "                 '-model', 'checkpoints/averaged-10-epoch.pt',\n",
        "                 '-src', 'data/valid.en',\n",
        "                ]\n",
        "\n",
        "    opts, unknown = parser.parse_known_args(base_args, namespace=opts)\n",
        "\n",
        "    model_opt = ArgumentParser.ckpt_model_opts(opts)\n",
        "    ArgumentParser.update_model_opts(model_opt)\n",
        "    ArgumentParser.validate_model_opts(model_opt)\n",
        "\n",
        "    opts.out_file = './out.txt'\n",
        "    return opts, model_opt\n",
        "\n",
        "\n",
        "def build_dataset(src_path, tgt_path):\n",
        "    src_data = {\"reader\": onmt.inputters.str2reader[\"text\"].from_opt(opts), \"data\": src_path}\n",
        "    tgt_data = {\"reader\": onmt.inputters.str2reader[\"text\"].from_opt(opts), \"data\": tgt_path}\n",
        "    _readers, _data = onmt.inputters.Dataset.config(\n",
        "        [('src', src_data), ('tgt', tgt_data)])\n",
        "\n",
        "    dataset = onmt.inputters.Dataset(\n",
        "        fields, readers=_readers, data=_data,\n",
        "        sort_key=onmt.inputters.str2sortkey[\"text\"])\n",
        "\n",
        "    return dataset\n",
        "\n",
        "def build_translator(opts, model, dataset, fields, tgt_path):\n",
        "    scorer = onmt.translate.GNMTGlobalScorer.from_opt(opts)\n",
        "\n",
        "    translator = Translator.from_opt(\n",
        "        model,\n",
        "        fields,\n",
        "        opts,\n",
        "        model_opt,\n",
        "        global_scorer=scorer,\n",
        "        out_file=opts.out_file,\n",
        "        report_align=False,\n",
        "        report_score=True\n",
        "    )\n",
        "\n",
        "    builder = onmt.translate.TranslationBuilder(\n",
        "        dataset, fields, opts.n_best, opts.replace_unk, tgt_path,\n",
        "        opts.phrase_table\n",
        "    )\n",
        "\n",
        "    return translator, scorer, builder\n",
        "\n",
        "# Visualización de atenciones\n",
        "def draw(data, x, y, ax):\n",
        "    seaborn.heatmap(data,\n",
        "                    xticklabels=x, square=True, yticklabels=y, vmin=0.0, vmax=1.0,\n",
        "                    cbar=False, ax=ax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyk-K3pjXrwX"
      },
      "source": [
        "## Traducción EN-DE\n",
        "\n",
        "Utilizaremos un modelo Transformer para generar traducciones desde el inglés al alemán.\n",
        "\n",
        "Al generar estas traducciones, más que enfocarnos en ella nos interesa visualizar las atenciones que pone el modelo, en este caso enfoccandonos a las atenciones que el decoder del transformer pone sobre el resultado del encoder. En la literatura esta atención a veces se le llama **cross-attention**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bPAiUhBHBOa"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = 'checkpoints/averaged-10-epoch.pt'\n",
        "config_path = 'checkpoints/config.yaml'\n",
        "\n",
        "checkpoint, fields, opts = get_checkpoint_data(checkpoint_path)\n",
        "opts, model_opt = update_opts(opts, config_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86sNAG3SvltA"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W611RBjobtIJ"
      },
      "source": [
        "Como siempre, primero creamos el dataset y el modelo. También precargamos los pesos al modelo. Como estamos usando OpenNMT, creamos también un objeto del tipo `Translator` que nos ayudará a generar las traducciones de forma más limpia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YirtJgxWLUzg"
      },
      "outputs": [],
      "source": [
        "src = 'data/valid.en'\n",
        "tgt = 'data/valid.de'\n",
        "\n",
        "dataset = build_dataset(src, tgt)\n",
        "data_iter = onmt.inputters.OrderedIterator(\n",
        "                dataset=dataset,\n",
        "                device=device,\n",
        "                batch_size=16,\n",
        "                train=False,\n",
        "                sort=False,\n",
        "                sort_within_batch=True,\n",
        "                shuffle=True,\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz0XHiijGT-p"
      },
      "outputs": [],
      "source": [
        "model = build_model(model_opt, opts, fields, checkpoint)\n",
        "model.to(device)\n",
        "\n",
        "translator, scorer, builder = build_translator(opts, model, dataset, fields, tgt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcBaOJ8-eLaK"
      },
      "source": [
        "Ahora, utilizando un batch aleatorio del set de validación. Veremos la traducción generada y mostraremos las atenciones que utiliza el modelo sobre el encoder.\n",
        "\n",
        "**Importante.** Por limitaciones de la API de OpenNMT, solo se visualiza el primer head de las atenciones en la última capa del Transformer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJhXhsSFGT8M"
      },
      "outputs": [],
      "source": [
        "for batch in data_iter:\n",
        "    trans_batch = translator.translate_batch(\n",
        "        batch=batch, src_vocabs=dataset.src_vocabs,\n",
        "        attn_debug=True)\n",
        "    translations = builder.from_batch(trans_batch)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZeJuoaJTZZP"
      },
      "outputs": [],
      "source": [
        "# Seleccionamos aleatoriamente alguno de los elementos del batch\n",
        "translation = random.choice(translations)\n",
        "attns = translation.attns[0]\n",
        "attns = attns.cpu()\n",
        "\n",
        "x_len = len(translation.src_raw)\n",
        "attns = attns[:,:x_len]\n",
        "\n",
        "# Agregamos el token de término a la predicción\n",
        "tgt = translation.pred_sents[0] + ['[EOS]']\n",
        "\n",
        "fig, axs = plt.subplots(1,1, figsize=(18, 10))\n",
        "draw(attns, translation.src_raw, tgt, ax=axs)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flpPAFaJfm5H"
      },
      "source": [
        "## Actividad 2\n",
        "\n",
        "Responda las preguntas a continuación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBws-SJlfegy"
      },
      "source": [
        "En el archivo de configuración tenemos la siguiente información:\n",
        "\n",
        "```\n",
        "...\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 8\n",
        "...\n",
        "```\n",
        "Al generar el gráfico anterior, solo lo estamos visualizando las cross attentions para una capa y una \"head\" del modelo. **¿Cuántos gráficos tenedremos si es que pudiesemos visualizar todas las cross-attentions?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "QAoaVy_lTZTt"
      },
      "outputs": [],
      "source": [
        "R = 0 # @param{type: \"number\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6NvF17ugJIe"
      },
      "source": [
        "El decoder del Transformer, no solo utiliza este tipo de atenciones, también utiliza las del tipo self-attention. Si estuvieramos haciendo decoding de una traducción en el paso T=5, es decir generando el 5to token de salida , tal y como se muestra en la siguiente imágen.\n",
        "\n",
        "![](https://www.guru99.com/images/1/111318_0848_seq2seqSequ1.png)\n",
        "\n",
        "Si visualizaramos las atenciones de self-attention **¿Qué dimensiones tendría la matriz mostrada?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y7ZNUF21TZQ5"
      },
      "outputs": [],
      "source": [
        "R = '0x0' # @param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfhYRZPwixQO"
      },
      "source": [
        "**Responda si la siguiente afirmación es verdadera o falsa.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3l1DFguvM8M"
      },
      "source": [
        "En el decoder de un transformer, como lo vimos en clase, no es necesario enmascarar \"el futuro\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "47kUv48BvNLH"
      },
      "outputs": [],
      "source": [
        "R = '' #@param [\"\", \"Verdadero\", \"Falso\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXHjM86RvgOy"
      },
      "source": [
        "En un Transformer, el positional encoding se utiliza como **única** fuente de información del orden de la secuencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-hUpg60NvikJ"
      },
      "outputs": [],
      "source": [
        "R = '' #@param [\"\", \"Verdadero\", \"Falso\"]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}